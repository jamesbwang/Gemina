 Studies of various characteristics of the human face indicate that it contains a wealth of information about health status. Most studies involve objective measurement of facial features as correlated with historical health information. But some individuals also claim to be adept at intuitively gauging mortality based solely upon a quick glance at a person 's photograph. To test this claim , we invited 12 such individuals to see if they could tell if a person was alive or dead based solely on a brief examination of his or her photograph. All photos used in the experiment were transformed into a uniform gray scale and counterbalanced across eight categories as follows: gender , age , gaze direction , glasses , head position , smile , hair color , and image resolution. Participants examined 404 photographs displayed on a computer monitor , one photo at a time , each shown for a maximum of 8seconds. Half of the individuals in the photos were deceased , and half were alive at the time the experiment was conducted. Participants were asked to indicate if they thought the person in a photo was living or deceased by pressing an appropriate button. Overall , mean accuracy on this task was 53.6 % , where 50 % was expected by chance ( P = .005 , two tail). Statistically significant accuracy was independently obtained in 5 of the 12 participants. We also collected 32-channel electrocortical recordings and observed a robust difference between images of deceased individuals correctly vs. incorrectly classified in the early event related potential at 100ms post-stimulus onset. We then applied machine learning techniques to classify the photographs based on 11 image characteristics; both random forest<disease> and logistic regression machine learning approaches were used , and both classifiers failed to achieve accuracy above chance level. Our results suggest that some individuals can intuitively assess mortality based on some as-yet unknown features of the face.