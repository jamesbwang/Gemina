 The validity of clinical trial results is influenced by researchers ' decisions regarding the management of missing data. Inadequate management of missing data has been identified as a significant source of bias that can result in an overestimation of drug efficacy. Transparency related to the management of missing data is essential to assess the strength of evidence reported in publications. In a subset of 17 randomised clinical trials for two new antidepressant medications , we present a case study in which we examined investigators ' decisions regarding how to handle missing data and if their chosen method took into account , possible violations of analytic requirements that could affect results. The majority of trials ( 76 %) concluded that there was a benefit of antidepressant treatment and in 94 % the methodology for handling missing data was identifiable. Of these , 50 % imputed data using the last observation carried forward and half used a mixed-effects model repeated measure approach. Most reports did not provide a rationale for the method used , and no trials described analyses regarding differences between completers and dropouts. Sensitivity analysis was inconsistently reported and correction for multiple comparisons was not uniformly applied. Lack of transparency for analytic choices related to handling of missing data testing was common in this subset of RCTs. Because management of missing data can directly influence the quality of study results , it is critical that journal editors develop and enforce standards for methodological transparency.