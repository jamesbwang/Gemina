 Individuals who have lost normal pathways for communication need augmentative and alternative communication ( AAC) devices. In this study , we propose a new electrooculogram ( EOG)- based human-computer interface ( HCI) paradigm for AAC that does not require a user 's voluntary eye movement<symptom> for binary yes/no communication by patients in locked-in state ( LIS). The proposed HCI uses a horizontal EOG elicited by involuntary auditory oculogyric reflex , in response to a rotating sound<symptom> source. In the proposed HCI paradigm , a user was asked to selectively attend to one of two sound sources rotating in directions opposite to each other , based on the user 's intention. The user 's intentions could then be recognised by quantifying EOGs. To validate its performance , a series of experiments was conducted with ten healthy subjects , and two patients with amyotrophic lateral sclerosis ( ALS). The online experimental results exhibited high-classification accuracies of 94 % in both healthy subjects and ALS patients in cases where decisions were made every six seconds. The ALS patients also participated in a practical yes/no communication experiment with 26 or 30 questions with known answers. The accuracy of the experiments with questionnaires was 94 % , demonstrating that our paradigm could constitute an auxiliary AAC system for some LIS patients.