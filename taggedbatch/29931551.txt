 Humans recognize transformed images from a very small number of samples. Inspired by this idea , we evaluate a classification method that requires only one sample per class , while providing invariance to image transformations generated by a compact group. This method is based on signatures computed for images. We test and illustrate this theory through simulations that highlight the role of image structure and sampling density , as well as how the signatures are constructed. We extend the existing theory to account for variations in recognition accuracy due to image structure.