 Unmanned aerial vehicles ( UAVs) are an inexpensive platform for collecting remote sensing images , but UAV images suffer from a content loss problem caused by noise. In order to solve the noise problem of UAV images , we propose a new methods to denoise UAV images. This paper introduces a novel deep neural network method based on generative adversarial learning to trace the mapping relationship between noisy and clean images. In our approach , perceptual reconstruction loss is used to establish a loss equation that continuously optimizes a min-max game theoretic model to obtain better UAV image denoising results. The generated denoised images by the proposed method enjoy clearer ground objects edges and more detailed textures of ground objects. In addition to the traditional comparison method , denoised UAV images and corresponding original clean UAV images were employed to perform image matching based on local features. At the same time , the classification experiment on the denoised images was also conducted to compare the denoising results of UAV images with others. The proposed method had achieved better results in these comparison experiments.