 According to embodied cognition accounts , viewing others ' facial emotion can elicit the respective emotion representation in observers which entails simulations of sensory , motor , and contextual experiences. In line with that , published research found viewing others ' facial emotion to elicit automatic matched facial<symptom> muscle activation , which was further found to facilitate emotion recognition. Perhaps making congruent facial<symptom> muscle activity explicit produces an even greater recognition advantage. If there is conflicting sensory information , i.e. , incongruent facial<symptom> muscle activity , this might impede recognition. The effects of actively manipulating facial<symptom> muscle activity on facial emotion recognition from videos were investigated across three experimental conditions: ( a) explicit imitation of viewed facial emotional expressions ( stimulus-congruent condition) , ( b) pen-holding with the lips ( stimulus-incongruent condition) , and ( c) passive viewing ( control condition). It was hypothesised that ( 1) experimental condition ( a) and ( b) result in greater facial<symptom> muscle activity than ( c) , ( 2) experimental condition ( a) increases emotion recognition accuracy from others ' faces compared to ( c) , ( 3) experimental condition ( b) lowers recognition accuracy for expressions with a salient facial feature in the lower , but not the upper face area , compared to ( c). Participants ( 42 males , 42 females) underwent a facial emotion recognition experiment ( ADFES-BIV) while electromyography ( EMG) was recorded from five facial<symptom> muscle sites. The experimental conditions ' order was counter-balanced. Pen-holding caused stimulus-incongruent facial<symptom> muscle activity for expressions with facial feature saliency in the lower face region , which reduced recognition of lower face region emotions. Explicit imitation caused stimulus-congruent facial<symptom> muscle activity without modulating recognition. Methodological implications are discussed.