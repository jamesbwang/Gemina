  Recent theories suggest that familiar faces have a robust representation in memory because they have been encountered over a wide variety of contexts and image changes ( e.g. lighting , viewpoint and expression). By contrast , unfamiliar faces are encountered only once , and so they do not benefit from such richness of experience and are represented based on image-specific details. In this registered report , we used a repeat detection task to test whether familiar faces are recognized better than unfamiliar faces across image changes. Participants viewed a stream of more than 1000 celebrity face images for 0.5 s each , any of which might be repeated at a later point and has to be detected. Some participants saw the same image at repeats , while others saw a different image of the same face. A post-experimental familiarity check allowed us to determine which celebrities were and were not familiar to each participant. We had three predictions: ( i) detection would be better for familiar than unfamiliar faces , ( ii) detection would be better across same rather than different images , and ( iii) detection of familiar faces would be comparable across same and different images , but detection of unfamiliar faces would be poorer across different images. We obtained support for the first two predictions but not the last. Instead , we found that repeat detection of faces , regardless of familiarity , was poorer across different images. Our study suggests that the robustness of familiar face recognition may have limits , and that under some conditions , familiar face recognition can be just as influenced by image changes as unfamiliar face recognition.