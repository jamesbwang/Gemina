  Prior research has shown that musical beats are salient at the level of the cortex in humans. Yet below the cortex there is considerable sub-cortical processing that could influence beat perception. Some biases , such as a tempo preference and an audio frequency bias for beat timing , could result from sub-cortical processing. Here , we used models of the auditory-nerve and midbrain-level amplitude modulation filtering to simulate sub-cortical neural activity to various beat-inducing stimuli , and we used the simulated activity to determine the tempo or beat frequency of the music. First , irrespective of the stimulus being presented , the preferred tempo was around 100 beats per minute , which is within the range of tempi where tempo discrimination and tapping accuracy are optimal. Second , sub-cortical processing predicted a stronger influence of lower audio frequencies on beat perception. However , the tempo identification algorithm that was optimized for simple stimuli often failed for recordings of music. For music , the most highly synchronized model activity occurred at a multiple of the beat frequency. Using bottom-up processes alone is insufficient to produce beat-locked activity. Instead , a learned and possibly top-down mechanism that scales the synchronization frequency to derive the beat frequency greatly improves the performance of tempo identification.