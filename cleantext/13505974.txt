  Currently , visual sensors are becoming increasingly affordable and fashionable , acceleratingly the increasing number of image data. Image retrieval has attracted increasing interest due to space exploration , industrial , and biomedical applications. Nevertheless , designing effective feature representation is acknowledged as a hard yet fundamental issue. This paper presents a fusion feature representation called a hybrid histogram descriptor ( HHD) for image retrieval. The proposed descriptor comprises two histograms jointly: a perceptually uniform histogram which is extracted by exploiting the color and edge orientation information in perceptually uniform regions; and a motif co-occurrence histogram which is acquired by calculating the probability of a pair of motif patterns. To evaluate the performance , we benchmarked the proposed descriptor on RSSCN7 , AID , Outex-00013 , Outex-00014 and ETHZ-53 datasets. Experimental results suggest that the proposed descriptor is more effective and robust than ten recent fusion-based descriptors under the content-based image retrieval framework. The computational complexity was also analyzed to give an in-depth evaluation. Furthermore , compared with the state-of-the-art convolutional neural network ( CNN)- based descriptors , the proposed descriptor also achieves comparable performance , but does not require any training process.