  We present a method of segmenting human parts in depth images , when provided the image positions of the body parts. The goal is to facilitate per-pixel labelling of large datasets of human images , which are used for training and testing algorithms for pose estimation and automatic segmentation. A common technique in image segmentation is to represent an image as a two-dimensional grid graph , with one node for each pixel and edges between neighbouring pixels. We introduce a graph with distinct layers of nodes to model occlusion of the body by the arms. Once the graph is constructed , the annotated part positions are used as seeds for a standard interactive segmentation algorithm. Our method is evaluated on two public datasets containing depth images of humans from a frontal view. It produces a mean per-class accuracy of 93.55 % on the first dataset , compared to 87.91 % ( random forest<disease> and graph cuts) and 90.31 % ( random forest<disease> and Markov random field). It also achieves a per-class accuracy of 90.60 % on the second dataset. Future work can experiment with various methods for creating the graph layers to accurately model occlusion.