  In computer vision , illumination is considered to be a problem that needs to be ` solved '. The colour cast due to illumination is removed to support colour-based image recognition and stable tracking ( in and out of shadows) , among other tasks. In this paper , I review historical and current algorithms for illumination estimation. In the classical approach , the illuminant colour is estimated by an ever more sophisticated analysis of simple image summary statistics often followed by a bias correction step. Bias correction is a function applied to the estimates made by a given illumination estimation algorithm to correct consistent errors in the estimations. Most recently , the full power , and much higher complexity , of deep learning has been deployed ( where , effectively , the definition of the image statistics of interest and the type of analysis carried out are found as part of an overall optimization). In this paper , I challenge the orthodoxy of deep learning , i.e. that it is the best approach for illuminant estimation. We instead focus on the final bias correction stage found in many simple illumination estimation algorithms. There are two key insights in our method. First , we argue that the bias must be corrected in an exposure invariant way. Second , we show that this bias correction amounts to ` solving for a homography '. Homography-based illuminant estimation is shown to deliver leading illumination estimation performance ( at a very small fraction of the complexity of deep learning methods).